---
layout: "@layouts/MDPage.astro"
title: Wie ich generative KI in meinem Blog und Alltag verwende
date: 2025-04-02
---

_Diese Seite ist inspiriert von [Damola Morenikeji](https://www.bydamo.la/p/ai-manifesto/)._

Ziel ist es, Vertrauen und Transparenz zu fördern.

Letztes Update: April 2025

_This page is also available in [English](/en/ai/)._

### Schreiben

Ich setze KI-gestützte Sprachmodelle (LLMs) unterstützend ein – niemals ersetzend.
Sie helfen mir beim Formatieren, Korrigieren und Optimieren von Inhalten.

Kein Text wird vollständig von einem LLM verfasst.
Bilder, die KI-generiert sind, werden entsprechend gekennzeichnet.

Ich nutze dafür lokale KI-Tools auf meinem MacBook.
Für die meisten der oben genannten Aufgaben verwende ich [Ollama](https://ollama.ai/),
[Enchanted](https://github.com/gluonfield/enchanted),
und [LM Studio](https://lmstudio.ai/).

#### Eine Randnotiz

Ich lasse das LLM zwar nicht meine ersten Entwürfe schreiben,
doch nutze ich sie, um meine Texte zu verbessern.
Beim Schreiben geht es schließlich nicht darum,
die KI für mich denken zu lassen, sondern sie als Werkzeug einzusetzen
– zum Beispiel die Lesbarkeit zu verbessern.

Eine KI oder ein Sprachmodell ist letztlich nichts anderes als eine Maschine
– sie denkt nicht und weiß nicht, was wahr oder falsch ist.
Was sie jedoch hervorragend beherrscht, ist das Strukturieren großer Informationsmengen,
um diese schnell und effizient zugänglich zu machen.
Und das ist, bei allem Vorbehalt, durchaus beeindruckend.

### Im Alltag

LLMs sind nützlich um:

- Antworten auf knifflige Fragen zu finden.
- komplexe Konzepte aufzuschlüsseln.
- Artikel zusammenfassen.
- Informationen aus langen Texten zu extrahieren.
- Code automatisch zu vervollständigen.
- um Texte und Code zu formatieren, was manuell sehr zeitaufwendig ist.

Natürlich könnte ich ein LLM auch einfach bitten,
mir eine lustige Geschichte zu erzählen.
Aber damit wäre es dann wohl doch ein wenig unterfordert.

Ich verwende auch den Sprachmodus von ChatGPT.
Wenn ich unterwegs bin, höre ich viele Podcasts.
Stoße ich dabei auf etwas Unklares oder Interesaantes,
kann ich unkompliziert mit dem Sprachmodel reden und es mir erklären lassen.

Bei der Programmierung nutze ich Code-Vervollständigung.
Nach einer kurzen Testphase mit Copilot entschied ich mich für lokale LLMs mit Ollama
– sie bieten mehr Privatsphäre und Offline-Nutzung.
Besonders gut funktioniert das mit dem Editor [Zed](https://zed.dev)
und der VSCode-Erweiterung [Continue](https://continue.dev/).
Seit Mitte 2024 verwende ich außerdem [fabric](https://github.com/danielmiessler/fabric),
ein KI-Framework mit über 200 nützlichen Prompt-Mustern für wiederkehrende Aufgaben.
